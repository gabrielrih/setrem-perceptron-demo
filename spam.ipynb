{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1044271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3fb5971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.4, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.activation_func = self._unit_step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def _unit_step_func(self, x):\n",
    "        return np.where(x>=0, 1, -1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        _, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)  # Init weights\n",
    "        self.bias = 0\n",
    "        \n",
    "        y_ = np.array([1 if i > 0 else -1 for i in y])\n",
    "        \n",
    "        print(f\"Initial weights and bias: {self.weights}, {self.bias}\")\n",
    "        for i in range(self.epochs):\n",
    "            print(f\"Epoch: {i}\")\n",
    "            for ind, x_i in enumerate(X):\n",
    "                # [0, 0] * [0, 0] + 0\n",
    "                linear_out = np.dot(x_i, self.weights) + self.bias\n",
    "                y_pred = self.activation_func(linear_out)\n",
    "                print(f\"\\tPredicting {x_i}: {linear_out}\\n\\tAfter activation: {y_pred}. Correct: {y_[ind]}\")  \n",
    "                update = self.learning_rate * (y_[ind] - y_pred)\n",
    "                print(f\"\\tProposed update: {update}\")\n",
    "                update_w = update * x_i\n",
    "                self.weights += update_w\n",
    "                self.bias += update\n",
    "                print(f\"New weights and bias: {self.weights}, {self.bias}\\n--\\n\")\n",
    "            print(f\"Weights: {self.weights} and {self.bias}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_out = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self.activation_func(linear_out)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b1bd1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamIdentifier:\n",
    "    def __init__(self):\n",
    "        self._dataset = SpamIdentifier.load_dataset()\n",
    "        self.X_train = self._dataset.data\n",
    "        self.y_train = self._dataset.target\n",
    "        print(f'Train data: \\n {self.X_train} {self.y_train}')\n",
    "    \n",
    "    def train(self, learning_rate=0.01, epochs=10) -> Perceptron:\n",
    "        p = Perceptron(learning_rate, epochs)\n",
    "        p.fit(self.X_train, self.y_train)\n",
    "        return p\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_if_it_is_spam(p: Perceptron, X_test) -> bool:\n",
    "        prediction = p.predict(X_test)\n",
    "        if prediction == 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset():\n",
    "        with open(r'spam_dataset.csv') as csv_file:\n",
    "            data_reader = csv.reader(csv_file)\n",
    "            feature_names = next(data_reader)[:-1]\n",
    "            data = []\n",
    "            target = []\n",
    "            for row in data_reader:\n",
    "                features = row[:-1]\n",
    "                label = row[-1]\n",
    "                data.append([float(num) for num in features])\n",
    "                target.append(int(label))\n",
    "            \n",
    "            data = np.array(data)\n",
    "            target = np.array(target)\n",
    "        return Bunch(data=data, target=target, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1f3f5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      " [[1. 0. 1. 1.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 1. 1. 1.]\n",
      " [1. 1. 0. 1.]\n",
      " [0. 0. 1. 0.]] [-1  1 -1 -1  1  1]\n",
      "Initial weights and bias: [0. 0. 0. 0.], 0\n",
      "Epoch: 0\n",
      "\tPredicting [1. 0. 1. 1.]: 0.0\n",
      "\tAfter activation: 1. Correct: -1\n",
      "\tProposed update: -0.8\n",
      "New weights and bias: [-0.8  0.  -0.8 -0.8], -0.8\n",
      "--\n",
      "\n",
      "\tPredicting [1. 1. 0. 0.]: -1.6\n",
      "\tAfter activation: -1. Correct: 1\n",
      "\tProposed update: 0.8\n",
      "New weights and bias: [ 0.   0.8 -0.8 -0.8], 0.0\n",
      "--\n",
      "\n",
      "\tPredicting [0. 0. 1. 1.]: -1.6\n",
      "\tAfter activation: -1. Correct: -1\n",
      "\tProposed update: 0.0\n",
      "New weights and bias: [ 0.   0.8 -0.8 -0.8], 0.0\n",
      "--\n",
      "\n",
      "\tPredicting [0. 1. 1. 1.]: -0.8\n",
      "\tAfter activation: -1. Correct: -1\n",
      "\tProposed update: 0.0\n",
      "New weights and bias: [ 0.   0.8 -0.8 -0.8], 0.0\n",
      "--\n",
      "\n",
      "\tPredicting [1. 1. 0. 1.]: 0.0\n",
      "\tAfter activation: 1. Correct: 1\n",
      "\tProposed update: 0.0\n",
      "New weights and bias: [ 0.   0.8 -0.8 -0.8], 0.0\n",
      "--\n",
      "\n",
      "\tPredicting [0. 0. 1. 0.]: -0.8\n",
      "\tAfter activation: -1. Correct: 1\n",
      "\tProposed update: 0.8\n",
      "New weights and bias: [ 0.   0.8  0.  -0.8], 0.8\n",
      "--\n",
      "\n",
      "Weights: [ 0.   0.8  0.  -0.8] and 0.8\n"
     ]
    }
   ],
   "source": [
    "spam = SpamIdentifier()\n",
    "p = spam.train(learning_rate = 0.4, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c9ae0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_it_is_spam(X_test):\n",
    "    print(f'Test data: {X_test}')\n",
    "    is_spam = SpamIdentifier.predict_if_it_is_spam(p, X_test)\n",
    "    if is_spam:\n",
    "        print('The email is spam')\n",
    "    else:\n",
    "        print('The email is not spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0af94a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: [1 0 0 1]\n",
      "The email is spam\n"
     ]
    }
   ],
   "source": [
    "# Testing a new data expecting to be spam\n",
    "X_test = np.array([1, 0, 0, 1])\n",
    "check_if_it_is_spam(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a2e48cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: [0 0 0 1]\n",
      "The email is spam\n"
     ]
    }
   ],
   "source": [
    "# Testing a new data expecting to NOT be spam\n",
    "X_test = np.array([0, 0, 0, 1])\n",
    "check_if_it_is_spam(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
